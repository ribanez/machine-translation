{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_identity30 = \"data/identity30.txt\"\n",
    "\n",
    "if not os.path.exists(data_identity30):\n",
    "    \n",
    "    !wget -O $data_identity30 http://dunbrack.fccc.edu/Guoli/users_html/cullpdb_pc25_res3.0_R0.3_d181017_chains13327.20909"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs         length   Exptl.  resolution  R-factor FreeRvalue\r\n",
      "7ODCA       424      XRAY        1.600    0.20    0.23\r\n",
      "3SWHA       341      XRAY        2.650    0.25    0.30\r\n",
      "2AXPA       173      XRAY        2.500    0.26    0.29\r\n",
      "4EIUA       249      XRAY        1.900    0.18    0.21\r\n",
      "5LWAA       159      XRAY        1.650    0.17    0.20\r\n",
      "5OF3B       307      XRAY        2.910    0.23    0.27\r\n",
      "3T47A        81      XRAY        1.300    0.16    0.19\r\n",
      "2NUTC       196      XRAY        2.300    0.22    0.27\r\n",
      "3RC3A       677      XRAY        2.080    0.16    0.20\r\n"
     ]
    }
   ],
   "source": [
    "!head --lines 10 $data_identity30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_files(path_file):\n",
    "    \n",
    "    names_filter = []\n",
    "    \n",
    "    with open(path_file, \"r\") as freader:\n",
    "        \n",
    "        for idx, line in enumerate(freader):\n",
    "            \n",
    "            if idx == 0: continue\n",
    "            \n",
    "            data = line.split()\n",
    "            \n",
    "            name = data[0]\n",
    "            \n",
    "            if len(name) > 5: continue\n",
    "            \n",
    "            name_reference = name[:4].upper() + \"_dihedrals_chain_\" + name[-1].upper() + \".csv\"\n",
    "            \n",
    "            names_filter.append(name_reference)\n",
    "    \n",
    "    return names_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_filter = filter_files(path_file=data_identity30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names_filter[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_angle(angle, split = 1):\n",
    "\n",
    "    angle = int(1.0 * angle / split)\n",
    "\n",
    "    if angle < 0:\n",
    "\n",
    "        angle += 360\n",
    "\n",
    "    if angle >= 360:\n",
    "\n",
    "        angle = angle % 360\n",
    "\n",
    "    return angle\n",
    "\n",
    "\n",
    "def encoding_omega(omega):\n",
    "\n",
    "    omega = int(omega)\n",
    "\n",
    "    if omega < 0:\n",
    "\n",
    "        omega += 360\n",
    "\n",
    "    if omega >= 360:\n",
    "\n",
    "        omega = omega % 360\n",
    "\n",
    "    return 180 if 90 <= omega < 270 else 0\n",
    "\n",
    "\n",
    "def create_dictionary_phi(split = 1):\n",
    "\n",
    "    dictionary_phi = Dictionary()\n",
    "\n",
    "    n_ranges = int(1.0 * 360 / split)\n",
    "\n",
    "    for idx in range(n_ranges):\n",
    "\n",
    "        dictionary_phi.add_word(str(idx * 360))\n",
    "\n",
    "    return dictionary_phi\n",
    "\n",
    "\n",
    "def create_dictionary_ome():\n",
    "\n",
    "    dictionary_ome = Dictionary()\n",
    "\n",
    "    dictionary_ome.add_word(\"180\")\n",
    "\n",
    "    dictionary_ome.add_word(\"0\")\n",
    "\n",
    "    return dictionary_ome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "class ChainLoader:\n",
    "\n",
    "    def __init__(self, root_dir, sep=\";\", fixed=None, filter_by_names = None):\n",
    "\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "        self.sep = sep\n",
    "\n",
    "        self.fixed = fixed\n",
    "        \n",
    "        if filter_by_names is not None:\n",
    "            \n",
    "            self.names = []\n",
    "            \n",
    "            for name in sorted(glob(os.path.join(self.root_dir, '*.csv'))):\n",
    "                \n",
    "                name_reference = name[-26:]\n",
    "                \n",
    "                if name_reference in filter_by_names:\n",
    "                    \n",
    "                    self.names.append(name)\n",
    "                    \n",
    "        else:\n",
    "        \n",
    "            self.names = sorted(glob(os.path.join(self.root_dir, '*.csv')))\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.names) - 1 if self.fixed is None else self.fixed\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        return self.get_with_name(self.names[idx])\n",
    "\n",
    "    def get_with_name(self, name):\n",
    "\n",
    "        pri_seq = []\n",
    "\n",
    "        phi_seq = []\n",
    "\n",
    "        psi_seq = []\n",
    "\n",
    "        ome_seq = []\n",
    "\n",
    "        with open(name, \"r\") as pdb:\n",
    "\n",
    "            for index, line in enumerate(pdb):\n",
    "\n",
    "                if index == 0:\n",
    "\n",
    "                    continue\n",
    "\n",
    "                # CSV STRUCTURE\n",
    "                # RESNAME, RES_N, PHI, PSI, OMEGA\n",
    "\n",
    "                residue_values = line.split(self.sep)\n",
    "\n",
    "                resname = residue_values[0].strip().upper()\n",
    "\n",
    "                ang_phi = residue_values[2].strip()\n",
    "\n",
    "                ang_psi = residue_values[3].strip()\n",
    "\n",
    "                ang_ome = residue_values[4].strip()\n",
    "\n",
    "                pri_seq.append(resname)\n",
    "\n",
    "                phi_seq.append(float(ang_phi))\n",
    "\n",
    "                psi_seq.append(float(ang_psi))\n",
    "\n",
    "                ome_seq.append(float(ang_ome))\n",
    "\n",
    "        return pri_seq, phi_seq, psi_seq, ome_seq, name.split(\"/\")[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['P',\n",
       "  'S',\n",
       "  'P',\n",
       "  'R',\n",
       "  'E',\n",
       "  'Q',\n",
       "  'L',\n",
       "  'M',\n",
       "  'E',\n",
       "  'S',\n",
       "  'I',\n",
       "  'R',\n",
       "  'K',\n",
       "  'G',\n",
       "  'K',\n",
       "  'E',\n",
       "  'L',\n",
       "  'K',\n",
       "  'Q',\n",
       "  'A'],\n",
       " [0.0,\n",
       "  -70.7,\n",
       "  -54.18,\n",
       "  -82.22,\n",
       "  -59.78,\n",
       "  -80.68,\n",
       "  -73.9,\n",
       "  -68.2,\n",
       "  -71.36,\n",
       "  -76.03,\n",
       "  -65.35,\n",
       "  -69.29,\n",
       "  -70.41,\n",
       "  79.52,\n",
       "  -166.33,\n",
       "  -76.97,\n",
       "  -121.54,\n",
       "  -70.98,\n",
       "  -136.92,\n",
       "  -148.58],\n",
       " [122.98,\n",
       "  161.52,\n",
       "  -27.38,\n",
       "  -36.56,\n",
       "  -36.94,\n",
       "  -19.72,\n",
       "  -44.44,\n",
       "  -31.08,\n",
       "  -30.43,\n",
       "  -35.11,\n",
       "  -42.86,\n",
       "  -29.06,\n",
       "  -31.72,\n",
       "  -177.65,\n",
       "  158.06,\n",
       "  144.25,\n",
       "  151.77,\n",
       "  -172.1,\n",
       "  160.11,\n",
       "  0.0],\n",
       " [-179.17,\n",
       "  177.4,\n",
       "  177.59,\n",
       "  176.64,\n",
       "  -179.38,\n",
       "  173.79,\n",
       "  179.32,\n",
       "  177.53,\n",
       "  177.55,\n",
       "  176.57,\n",
       "  177.7,\n",
       "  175.6,\n",
       "  -177.32,\n",
       "  176.54,\n",
       "  177.89,\n",
       "  -178.78,\n",
       "  -168.57,\n",
       "  -168.13,\n",
       "  174.06,\n",
       "  180.0],\n",
       " '0020_3MN7_dihedrals_chain_S.csv')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl = ChainLoader(root_dir=\"/media/panceta_disk/DATA/CHAINS_SPLIT/train/\", \n",
    "                 sep=\";\", \n",
    "                 fixed=10,\n",
    "                 filter_by_names=names_filter\n",
    "                )\n",
    "\n",
    "cl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(root_dir, sep=\";\", fixed=None, output=\"data\", filter_file=\"data/identity30.txt\"):\n",
    "    \n",
    "    names_filter = filter_files(path_file=filter_file)\n",
    "    \n",
    "    cl = ChainLoader(root_dir=root_dir, sep=sep, fixed=fixed, filter_by_names=names_filter)\n",
    "    \n",
    "    src_path = open(output + \".ang\", \"w\")\n",
    "    \n",
    "    tgt_path = open(output + \".res\", \"w\")\n",
    "    \n",
    "    for idx in range(0, len(cl)):\n",
    "        \n",
    "        pri_seq, phi_seq, psi_seq, ome_seq, name = cl[idx]\n",
    "        \n",
    "        src_seq = []\n",
    "        \n",
    "        tgt_seq = []\n",
    "        \n",
    "        for jdx in range(0, len(pri_seq)):\n",
    "            \n",
    "            src_seq.append(str(encoding_angle(phi_seq[jdx])))\n",
    "            \n",
    "            src_seq.append(str(encoding_angle(psi_seq[jdx])))\n",
    "            \n",
    "            src_seq.append(str(encoding_omega(ome_seq[jdx])))\n",
    "            \n",
    "            tgt_seq.append(str(pri_seq[jdx]))\n",
    "            \n",
    "        src_path.write(\" \".join(src_seq) + \"\\n\") \n",
    "        \n",
    "        tgt_path.write(\" \".join(tgt_seq) + \"\\n\")\n",
    "        \n",
    "    src_path.close()\n",
    "                           \n",
    "    tgt_path.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing.ipynb  checkpoints  download.sh  preprocess.py  tmp\r\n",
      "README.md\t     data\t  generate.py  score.py       train.py\r\n",
      "__pycache__\t     data-bin\t  images       seq2seq\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(root_dir=\"/media/panceta_disk/DATA/CHAINS_SPLIT/train/\", \n",
    "               sep=\";\", \n",
    "               fixed=None, \n",
    "               output=\"data/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(root_dir=\"/media/panceta_disk/DATA/CHAINS_SPLIT/dev/\", \n",
    "               sep=\";\", \n",
    "               fixed=None, \n",
    "               output=\"data/eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(root_dir=\"/media/panceta_disk/DATA/CHAINS_SPLIT/test/\", \n",
    "               sep=\";\", \n",
    "               fixed=None, \n",
    "               output=\"data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2018-10-18 12:34:34] COMMAND: preprocess.py --source-lang ang --target-lang res --train-prefix data//train --valid-prefix data//eval --test-prefix data//test --dest-dir data-bin/tokenized.ang-res\n",
      "[2018-10-18 12:34:34] Arguments: {'source_lang': 'ang', 'target_lang': 'res', 'train_prefix': 'data//train', 'valid_prefix': 'data//eval', 'test_prefix': 'data//test', 'dest_dir': 'data-bin/tokenized.ang-res', 'threshold_src': 0, 'num_words_src': -1, 'threshold_tgt': 0, 'num_words_tgt': -1}\n",
      "[2018-10-18 12:34:34] COMMAND: preprocess.py --source-lang ang --target-lang res --train-prefix data//train --valid-prefix data//eval --test-prefix data//test --dest-dir data-bin/tokenized.ang-res\n",
      "[2018-10-18 12:34:34] Arguments: {'source_lang': 'ang', 'target_lang': 'res', 'train_prefix': 'data//train', 'valid_prefix': 'data//eval', 'test_prefix': 'data//test', 'dest_dir': 'data-bin/tokenized.ang-res', 'threshold_src': 0, 'num_words_src': -1, 'threshold_tgt': 0, 'num_words_tgt': -1}\n",
      "[2018-10-18 12:34:39] Built a source dictionary (ang) with 363 words\n",
      "[2018-10-18 12:34:39] Built a target dictionary (res) with 24 words\n",
      "[2018-10-18 12:35:16] Built a binary dataset for data//train.ang: 10118 sentences, 7138892 tokens, 0.000% replaced by unknown token\n",
      "[2018-10-18 12:35:20] Built a binary dataset for data//eval.ang: 1149 sentences, 816804 tokens, 0.000% replaced by unknown token\n",
      "[2018-10-18 12:35:25] Built a binary dataset for data//test.ang: 1227 sentences, 857778 tokens, 0.000% replaced by unknown token\n",
      "[2018-10-18 12:35:37] Built a binary dataset for data//train.res: 10118 sentences, 2386376 tokens, 0.000% replaced by unknown token\n",
      "[2018-10-18 12:35:38] Built a binary dataset for data//eval.res: 1149 sentences, 273034 tokens, 0.000% replaced by unknown token\n",
      "[2018-10-18 12:35:40] Built a binary dataset for data//test.res: 1227 sentences, 286744 tokens, 0.000% replaced by unknown token\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"data/\"\n",
    "\n",
    "!python preprocess.py --source-lang ang --target-lang res --train-prefix $DATA_PATH/train --valid-prefix $DATA_PATH/eval --test-prefix $DATA_PATH/test --dest-dir data-bin/tokenized.ang-res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cuda90]",
   "language": "python",
   "name": "conda-env-cuda90-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
